{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHmfOguPs9eTb3hs/HWdFh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "MPOKTJee1xvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalaciones para descargar las imágenes al entorno\n",
        "!pip install gdown --upgrade --no-cache-dir\n",
        "!pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q8j1NX75fft",
        "outputId": "581a563f-511e-46fc-a829-824af495091a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.169.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.38.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "AVUuj5gYHl73"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import io\n",
        "import os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crear dataset"
      ],
      "metadata": {
        "id": "4w56ci9V12ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparar el entorno para descargar los archivos\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "#Links de acceso público a las carpetas con las imágenes\n",
        "folder_ia = '14xM8jjGl7QPMDUkti6iUl4M1m6qcs4L1'\n",
        "folder_real = '1ruvbcczrUZ2W6rmmC7TvLUQxtOD_Cg3J'\n",
        "\n",
        "#Función para descargar las imágenes al entorno\n",
        "def download_files_from_folder(folder_id, output_folder, label):\n",
        "  query = f\"'{folder_id}' in parents\"\n",
        "  results = drive_service.files().list(q=query, fields='nextPageToken, files(id, name)').execute()\n",
        "  items = results.get('files', [])\n",
        "\n",
        "  if not items:\n",
        "    print('No hay archivos en la carpeta.')\n",
        "    return\n",
        "\n",
        "  carpeta_label = os.path.join(output_folder, label)\n",
        "  os.makedirs(carpeta_label, exist_ok=True)\n",
        "\n",
        "  for item in items:\n",
        "    file_id = item['id']\n",
        "    file_name = item['name']\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    fh = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(fh, request)\n",
        "    done = False\n",
        "    while not done:\n",
        "      status, done = downloader.next_chunk()\n",
        "    with open(os.path.join(carpeta_label, file_name), 'wb') as f:\n",
        "      f.write(fh.getbuffer())\n",
        "\n",
        "os.makedirs('dataset', exist_ok=True)\n",
        "\n",
        "download_files_from_folder(folder_ia, 'dataset', 'ia')\n",
        "print(f\"Carpeta fotos_ia completada.\")\n",
        "download_files_from_folder(folder_real, 'dataset', 'real')\n",
        "print(f\"Carpeta fotos_real completada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V70gSCOW5odJ",
        "outputId": "bb499740-4e4d-474d-abba-052b9c37c045"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carpeta fotos_ia completada.\n",
            "Carpeta fotos_real completada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparación de datos"
      ],
      "metadata": {
        "id": "Q4XKysEvA2-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparación de las imágenes\n",
        "\n",
        "#Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  #Cambiar resolución de imagen\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) #Normalizar los píxeles\n",
        "])\n",
        "\n",
        "data = datasets.ImageFolder('dataset', transform=transform)\n",
        "\n",
        "#Comprobar labels\n",
        "print(f\"Labels: {data.classes}\")\n",
        "print(f\"Mapping de labels: {data.class_to_idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqkq47g65ORO",
        "outputId": "36b979b2-4eea-44c9-fd15-71f95a80109e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: ['ia', 'real']\n",
            "Mapping de labels: {'ia': 0, 'real': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separación de sets\n",
        "train_size = int(len(data)*0.7) # 70% de contenido para el training set\n",
        "val_size = int(0.15 * len(data)) # 15% de contenido para el validation set\n",
        "test_size = int(len(data) - train_size - val_size) # 15% de contenido para el test set\n",
        "\n",
        "train, val, test = random_split(data, [train_size, val_size, test_size])\n",
        "\n",
        "# Crear los DataLoaders\n",
        "train_loader = DataLoader(train, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "-jzyfTbksH4x"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creación de modelos"
      ],
      "metadata": {
        "id": "kHEEjNroA5xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear los modelos\n",
        "\n",
        "#Resnet18 (pretrained)\n",
        "modelo_resnet = models.resnet18(pretrained=True)\n",
        "modelo_resnet.fc = nn.Linear(modelo_resnet.fc.in_features, 2)\n",
        "\n",
        "#MobileNetV2 (pretrained)\n",
        "modelo_mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "modelo_mobilenet.classifier[1] = nn.Linear(modelo_mobilenet.classifier[1].in_features, 2)\n",
        "\n",
        "#CNN\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    #Convolutional layers\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    #Fully connected layers\n",
        "    self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "    self.fc2 = nn.Linear(512, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "    #Flatten\n",
        "    x = x.view(-1, 128 * 28 * 28)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "modelo_cnn = CNN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLm3Qh8IvESN",
        "outputId": "2da50ee4-df81-41e2-f268-fbb9248a8856"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizar modelos\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "resnet_optimizer = torch.optim.Adam(modelo_resnet.parameters(), lr=0.001)\n",
        "mobilenet_optimizer = torch.optim.Adam(modelo_mobilenet.parameters(), lr=0.001)\n",
        "cnn_optimizer = torch.optim.Adam(modelo_cnn.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "yr3-klXcHcJX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar el device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "modelo_resnet = modelo_resnet.to(device)\n",
        "modelo_mobilenet = modelo_mobilenet.to(device)\n",
        "modelo_cnn = modelo_cnn.to(device)"
      ],
      "metadata": {
        "id": "LEKEXDLAJHjH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar modelos"
      ],
      "metadata": {
        "id": "27U0o2T6Ejzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, dataLoader, device):\n",
        "  # Poner modelo en modo evaluación\n",
        "  model.eval()\n",
        "\n",
        "  preds = []\n",
        "  labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for input, label in dataLoader:\n",
        "      input = input.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      output = model(input)\n",
        "      _, pred = torch.max(output, 1)\n",
        "\n",
        "      preds.extend(pred.cpu().numpy())\n",
        "      labels.extend(label.cpu().numpy())\n",
        "\n",
        "  # Calcular métricas\n",
        "  accuracy = accuracy_score(labels, preds)\n",
        "  precision = precision_score(labels, preds, average='weighted')\n",
        "  recall = recall_score(labels, preds, average='weighted')\n",
        "  f1 = f1_score(labels, preds, average='weighted')\n",
        "  matrix = confusion_matrix(labels, preds)\n",
        "\n",
        "  results = {\n",
        "      'accuracy': accuracy,\n",
        "      'precision': precision,\n",
        "      'recall': recall,\n",
        "      'f1 measure': f1,\n",
        "      'confusion matrix': matrix\n",
        "  }\n",
        "  return results"
      ],
      "metadata": {
        "id": "0ObAVp5mzONK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n",
        "  model.to(device)\n",
        "\n",
        "  best_acc = 0.0\n",
        "  for epoch in range(epochs):\n",
        "    # Poner modelo en modo evaluación\n",
        "    model.train()\n",
        "\n",
        "    # Fase entrenamiento\n",
        "    running_loss = 0.0\n",
        "    for input, label in train_loader:\n",
        "      input, label = input.to(device), label.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(input)\n",
        "      loss = criterion(output, label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    # Fase validación\n",
        "    metrics = evaluation(model, val_loader, device)\n",
        "    accuracy = metrics['accuracy']\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}|   Train loss: {running_loss/len(train_loader):.4f}|   Val accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Guardar el modelo\n",
        "    if accuracy > best_acc:\n",
        "      best_acc = accuracy\n",
        "      torch.save(model.state_dict(), f\"best_{type(model).__name__}.pth\")\n",
        "\n",
        "  print(f\"Training completado!\")"
      ],
      "metadata": {
        "id": "63V9djdyEltc"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'ResNet18': (modelo_resnet, resnet_optimizer),\n",
        "    'MobileNet': (modelo_mobilenet, mobilenet_optimizer),\n",
        "    'CNN': (modelo_cnn, cnn_optimizer)\n",
        "}\n",
        "\n",
        "for name, (model, optimizer) in models.items():\n",
        "    print(f\"\\nTraining {name}\")\n",
        "    training(model, train_loader, val_loader, criterion, optimizer, epochs=10, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wzzYyjKIFIw",
        "outputId": "95eb713d-276e-42fe-ff39-cd4edf53ad9b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ResNet18\n",
            "Epoch 1/10|   Train loss: 0.0816|   Val accuracy: 0.9333\n",
            "Epoch 2/10|   Train loss: 0.0259|   Val accuracy: 1.0000\n",
            "Epoch 3/10|   Train loss: 0.0060|   Val accuracy: 1.0000\n",
            "Epoch 4/10|   Train loss: 0.0019|   Val accuracy: 0.9667\n",
            "Epoch 5/10|   Train loss: 0.0011|   Val accuracy: 1.0000\n",
            "Epoch 6/10|   Train loss: 0.0020|   Val accuracy: 1.0000\n",
            "Epoch 7/10|   Train loss: 0.0010|   Val accuracy: 1.0000\n",
            "Epoch 8/10|   Train loss: 0.0008|   Val accuracy: 1.0000\n",
            "Epoch 9/10|   Train loss: 0.0003|   Val accuracy: 1.0000\n",
            "Epoch 10/10|   Train loss: 0.0003|   Val accuracy: 1.0000\n",
            "Training completado!\n",
            "\n",
            "Training MobileNet\n",
            "Epoch 1/10|   Train loss: 0.0001|   Val accuracy: 0.9667\n",
            "Epoch 2/10|   Train loss: 0.0002|   Val accuracy: 0.9667\n",
            "Epoch 3/10|   Train loss: 0.0008|   Val accuracy: 0.9667\n",
            "Epoch 4/10|   Train loss: 0.0003|   Val accuracy: 0.9667\n",
            "Epoch 5/10|   Train loss: 0.0002|   Val accuracy: 0.9667\n",
            "Epoch 6/10|   Train loss: 0.0002|   Val accuracy: 0.9667\n",
            "Epoch 7/10|   Train loss: 0.0049|   Val accuracy: 0.9667\n",
            "Epoch 8/10|   Train loss: 0.0002|   Val accuracy: 0.9333\n",
            "Epoch 9/10|   Train loss: 0.0215|   Val accuracy: 0.9333\n",
            "Epoch 10/10|   Train loss: 0.3022|   Val accuracy: 0.7667\n",
            "Training completado!\n",
            "\n",
            "Training CNN\n",
            "Epoch 1/10|   Train loss: 0.0928|   Val accuracy: 0.9667\n",
            "Epoch 2/10|   Train loss: 0.0364|   Val accuracy: 1.0000\n",
            "Epoch 3/10|   Train loss: 0.0155|   Val accuracy: 0.9667\n",
            "Epoch 4/10|   Train loss: 0.0067|   Val accuracy: 1.0000\n",
            "Epoch 5/10|   Train loss: 0.0015|   Val accuracy: 1.0000\n",
            "Epoch 6/10|   Train loss: 0.0010|   Val accuracy: 1.0000\n",
            "Epoch 7/10|   Train loss: 0.0005|   Val accuracy: 1.0000\n",
            "Epoch 8/10|   Train loss: 0.0002|   Val accuracy: 1.0000\n",
            "Epoch 9/10|   Train loss: 0.0002|   Val accuracy: 0.9667\n",
            "Epoch 10/10|   Train loss: 0.0002|   Val accuracy: 0.9667\n",
            "Training completado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "ShSmaPjKzOkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar modelos\n",
        "models = {\n",
        "    'ResNet18': modelo_resnet,\n",
        "    'MobileNetV2': modelo_mobilenet,\n",
        "    'Custom CNN': modelo_cnn\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "  print(f\"Evaluando modelo: {name}\")\n",
        "  model.load_state_dict(torch.load(f\"best_{type(model).__name__}.pth\"))\n",
        "  results[name] = evaluation(model, test_loader, device)\n",
        "\n",
        "# Imprimir resultados\n",
        "for model, metrics in results.items():\n",
        "    print(f'\\n{model} Performance:')\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"F1-Score: {metrics['f1 measure']:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(metrics['confusion matrix'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP-TsoRTEEmk",
        "outputId": "0d0de68e-cc92-4e1a-b3b1-c435a5a2b364"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando modelo: ResNet18\n",
            "Evaluando modelo: MobileNetV2\n",
            "Evaluando modelo: Custom CNN\n",
            "\n",
            "ResNet18 Performance:\n",
            "Accuracy: 0.9667\n",
            "Precision: 0.9685\n",
            "Recall: 0.9667\n",
            "F1-Score: 0.9665\n",
            "Confusion Matrix:\n",
            "[[12  1]\n",
            " [ 0 17]]\n",
            "\n",
            "MobileNetV2 Performance:\n",
            "Accuracy: 0.9333\n",
            "Precision: 0.9422\n",
            "Recall: 0.9333\n",
            "F1-Score: 0.9336\n",
            "Confusion Matrix:\n",
            "[[13  0]\n",
            " [ 2 15]]\n",
            "\n",
            "Custom CNN Performance:\n",
            "Accuracy: 0.8667\n",
            "Precision: 0.8921\n",
            "Recall: 0.8667\n",
            "F1-Score: 0.8616\n",
            "Confusion Matrix:\n",
            "[[ 9  4]\n",
            " [ 0 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debug"
      ],
      "metadata": {
        "id": "FOeAcBnY195a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###DEBUG --> borrar los contenidos de una carpeta###\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "carpeta = \"/content/dataset\"\n",
        "\n",
        "for archivo in os.listdir(carpeta):\n",
        "    ruta_completa = os.path.join(carpeta, archivo)\n",
        "    if os.path.isfile(ruta_completa) or os.path.islink(ruta_completa):\n",
        "        os.unlink(ruta_completa)\n",
        "    elif os.path.isdir(ruta_completa):\n",
        "        shutil.rmtree(ruta_completa)\n"
      ],
      "metadata": {
        "id": "-GPP3NDcLRly"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}